[{"assignees":[],"body":"## Bug\n\nBoth `ParseStream` (parser.go:26-28) and `Stream` (parser.go:57-58) silently discard lines that fail `json.Unmarshal` via bare `continue`. No counter, no warning, no signal to the caller.\n\n## Impact\n\nIf a `go test -json` fail event is corrupted in transit (partial write, pipe buffer split, mixed stdout), fo reports fewer failures than reality. Automation sees a false-clean result with no indication that data was lost.\n\n## Evidence\n\n```go\n// parser.go:26-28\nif err := json.Unmarshal(line, &event); err != nil {\n    continue // skip malformed lines — no warning, no count\n}\n```\n\nSame pattern at parser.go:57-58 in `Stream`.\n\n## Fix direction\n\nCount malformed lines. Options (pick one):\n1. Return a structured result that includes a `MalformedLines int` count\n2. Log a warning to stderr after parsing completes: `fo: warning: N malformed lines skipped`\n3. Accept a warning callback in the API\n\nThe key property: data loss must be visible to the caller.\n\n## Test\n\nFeed NDJSON with one corrupted fail-event line; assert the parser surfaces the malformed count (not silently zero failures).","closedAt":null,"createdAt":"2026-02-24T13:59:25Z","labels":[],"number":222,"state":"OPEN","title":"Malformed NDJSON lines silently dropped without warning","updatedAt":"2026-02-24T13:59:25Z"},{"assignees":[],"body":"## Bug\n\n`sarif.Read()` (reader.go:13) performs a single `json.Decoder.Decode()` without checking for EOF afterward. `json.Decoder` reads exactly one JSON value and stops — any trailing bytes are silently ignored.\n\n## Impact\n\nConcatenated or corrupted input like `{\"version\":\"2.1.0\",...}GARBAGE\\n{\"other\":\"data\"}` is accepted as valid SARIF. This masks upstream transport/pipeline corruption.\n\n## Evidence\n\n```go\n// reader.go:11-17\nfunc Read(r io.Reader) (*Document, error) {\n    var doc Document\n    if err := json.NewDecoder(r).Decode(&doc); err != nil {\n        return nil, fmt.Errorf(\"decode sarif: %w\", err)\n    }\n    return validateDocument(&doc)  // no EOF check\n}\n```\n\n## Fix\n\nAfter the first `Decode`, attempt a second `Decode` into `json.RawMessage` (or `any`) and require `io.EOF`:\n\n```go\nvar extra json.RawMessage\nif err := dec.Decode(&extra); err != io.EOF {\n    return nil, fmt.Errorf(\"unexpected trailing data after SARIF document\")\n}\n```\n\n## Test\n\n`ReadBytes([]byte(validSARIF + \"\\nGARBAGE\"))` should return an error.","closedAt":null,"createdAt":"2026-02-24T13:59:17Z","labels":[],"number":221,"state":"OPEN","title":"SARIF reader accepts trailing garbage after valid JSON","updatedAt":"2026-02-24T13:59:17Z"},{"assignees":[],"body":"## Bug\n\n`runWrap` (main.go:251) creates a `bufio.Scanner` without calling `scanner.Buffer()`, leaving the default 64KiB token limit. The testjson parser already sets a 1MiB buffer (parser.go:18), but `wrap sarif` doesn't.\n\n## Impact\n\nDiagnostic lines >64KiB trigger `bufio.ErrTooLong`, aborting the entire SARIF conversion with exit code 2. All findings are lost. This can happen with linters that emit long single-line diagnostics (generated code warnings, minified output, etc).\n\n## Evidence\n\n```go\n// main.go:251 — no Buffer() call\nscanner := bufio.NewScanner(stdin)\n\n// contrast with parser.go:16-18\nscanner := bufio.NewScanner(r)\nscanner.Buffer(make([]byte, 0, 64*1024), 1024*1024)  // 1MiB limit\n```\n\n## Fix\n\nAdd `scanner.Buffer(make([]byte, 0, 64*1024), 1024*1024)` to match testjson's limit.\n\n## Test\n\nFeed `runWrap` a diagnostic line >64KiB; assert it appears in the output SARIF.","closedAt":null,"createdAt":"2026-02-24T13:59:11Z","labels":[],"number":220,"state":"OPEN","title":"wrap sarif: default 64KiB scanner limit truncates long diagnostics","updatedAt":"2026-02-24T13:59:11Z"},{"assignees":[],"body":"## Bug\n\n`testjson.Stream()` checks `ctx.Err()` only inside the `for scanner.Scan()` loop body (parser.go:49). When stdin stalls (no data, no EOF), `scanner.Scan()` blocks indefinitely and context cancellation cannot interrupt it.\n\n## Impact\n\n`go test -json ./... | fo` in stream mode: if upstream hangs mid-stream, Ctrl-C cancels the context but `fo` remains stuck waiting for the next line or EOF. Requires a hard kill.\n\n## Evidence\n\n```go\n// parser.go:48-51\nfor scanner.Scan() {           // blocks here — not cancellable\n    if err := ctx.Err(); err != nil {  // only checked after Scan returns\n        return err\n    }\n```\n\n`runStream` (main.go:109) creates a cancellable context via `signal.NotifyContext`, but the cancellation never reaches the blocked read.\n\n## Fix direction\n\nMove the read into a goroutine and select on `ctx.Done()` vs a decoded-event channel — or close the underlying reader on cancel.\n\n## Test strategy\n\nCustom `io.Reader` that blocks forever in `Read`; cancel context after short timeout; assert `Stream` returns within deadline.","closedAt":null,"createdAt":"2026-02-24T13:59:05Z","labels":[],"number":219,"state":"OPEN","title":"Stream cancellation blocks on scanner read, Ctrl-C unresponsive","updatedAt":"2026-02-24T13:59:05Z"}]
